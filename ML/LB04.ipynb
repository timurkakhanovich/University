{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LB04: Ансамбли моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> ПСА 5 (Введение в машинное обучение). Мехмат, БГУ</div>\n",
    "    \n",
    "<div style=\"text-align: right\"> Тишуров Алексей, 2021 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный материал использует лицензию [Creative Commons CC BY-NC-SA 4.0.](https://creativecommons.org/licenses/by-nc-sa/4.0/) со всеми вытекающими. На прилагаемые к материалу датасеты лицензия не распространяется. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках данной лабораторной работы вы используете на практике два вида ансамблей: случайный лес (в реализации sklearn) и градиентный бустинг (в реализации lightgbm).\n",
    "\n",
    "Для установки lightgbm для linux точно будет достаточно conda install -c conda-forge lightgbm.\n",
    "На windows тоже должно сработать, но если будут проблемы, то может потребоваться VS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первой часте вы будете работать с датасетами из прошлых лаб (предсказание оттока у мобильного оператора и предсказание цены автомобиля). Необходимо использовать все наработки из прошлых лаб, пользовать кросс-валидацией, вычислять те же метрики. Для задачи с предсказанием цены автомобиля не забыть про возможность (если она нужна) преобразования целевой переменной.\n",
    "\n",
    "Таким образом, изучать датасет, его особенности и инженерить признаки снова не нужно, что ускоряет эту часть лабы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.1. Обучение случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, \\\n",
    "    GridSearchCV, train_test_split, KFold\n",
    "from eli5.sklearn import explain_rf_feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте наработки прошлой лабы (№3) и:\n",
    "1. Обучите на датасете про предсказания цены автомобиля RandomForestRegressor и проведите анализ качества работы вашей модели. \n",
    "2. Сравните с качеством работы отдельного дерева.\n",
    "3. Проанализируйте важность признаков с помощью feature_importances_\n",
    "4. Проведите оптимизацию гиперпараметров с помощью GridSearchCV, добавив новые параметры леса к параметрам одного дерева из прошлой лабы. Используйте для этого не очень большое количество деревьев в лесу. После увеличьте его в несколько раз с лучшими гиперпараметрами и сравните изменение качества"
   ]
  },
  {
   "source": [
    "## Loading and preprocess"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train-data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Mileage'] = train['Mileage'].apply(lambda x: str(x).split()[0])\n",
    "train['Power'] = train['Power'].apply(lambda x: str(x).split()[0])\n",
    "train['Engine'] = train['Engine'].apply(lambda x: str(x).split()[0])\n",
    "train['New_Price'] = train['New_Price'].apply(lambda x: str(x).split()).apply(lambda x: \n",
    "                                str(float(x[0])*100) if len(x) == 2 and x[1] == 'Cr' else x[0])\n",
    "\n",
    "train.fillna(value=0, inplace=True)\n",
    "train = train.replace('null', 0)\n",
    "\n",
    "train['Mileage'] = train['Mileage'].apply(lambda x: np.nan_to_num(float(x)))\n",
    "train['Power'] = train['Power'].apply(lambda x: np.nan_to_num(float(x)))\n",
    "train['Engine'] = train['Engine'].apply(lambda x: np.nan_to_num(float(x)))\n",
    "train['New_Price'] = train['New_Price'].apply(lambda x: np.nan_to_num(float(x)))\n",
    "\n",
    "train['Transmission'] = train['Transmission'].apply(lambda x: 1 if x == 'Automatic' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Location', 'Fuel_Type', 'Owner_Type']\n",
    "\n",
    "train_cat = pd.get_dummies(train[categorical_cols])\n",
    "train = pd.concat([train.drop(categorical_cols, axis=1), \n",
    "                    train_cat], axis=1)\n",
    "train.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "transmission = train['Transmission']\n",
    "train.drop('Transmission', axis=1, inplace=True)\n",
    "train.insert(8, 'Transmission', transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train['Price'].copy(deep=True).to_numpy()\n",
    "train.drop(['Price'], axis=1, inplace=True)"
   ]
  },
  {
   "source": [
    "## Features transform"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "real_features = scaler.fit_transform(train.iloc[:, :7])\n",
    "rest_features = train.iloc[:, 7:].to_numpy()\n",
    "\n",
    "X = np.copy(np.hstack([real_features, rest_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer()\n",
    "y = pt.fit_transform(Y.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "source": [
    "## Cross-validation initializing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "source": [
    "## RandomForestRegressor initializing and fitting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(reg, X, y, cv=cv)\n",
    "y_pred = pt.inverse_transform(y_pred.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16.87725132672729, 1.5123879265281241)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "mean_squared_error(Y, y_pred), mean_absolute_error(Y, y_pred)"
   ]
  },
  {
   "source": [
    "#### При количестве деревьев 100 и 120 качество сильно не меняется. Так как качество алгоритма близится к определенной асимптоте, можно остановиться на количестве деревьев 100. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree = DecisionTreeRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(reg_tree, X, y, cv=cv)\n",
    "y_pred = pt.inverse_transform(y_pred.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(23.227966337027578, 1.9482722384149234)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "mean_squared_error(Y, y_pred), mean_absolute_error(Y, y_pred)"
   ]
  },
  {
   "source": [
    "#### Как можно видеть, качество ансамбля деревьев несколько лучше качества одного дерева."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Feature importance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1, random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Explanation(estimator='RandomForestRegressor(n_jobs=-1, random_state=0)', description='\\nRandom forest feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=True, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='Power', weight=0.597044956306314, std=0.012998926742322647, value=None), FeatureWeight(feature='Year', weight=0.25947569447634433, std=0.0076376849669421674, value=None), FeatureWeight(feature='Engine', weight=0.04843488243351098, std=0.010380042277864442, value=None), FeatureWeight(feature='Mileage', weight=0.020648849542074754, std=0.003481978707924615, value=None), FeatureWeight(feature='Kilometers_Driven', weight=0.019752851171583583, std=0.0026004208540644762, value=None), FeatureWeight(feature='Transmission', weight=0.009077144445283512, std=0.003209000709993928, value=None), FeatureWeight(feature='Location_Kolkata', weight=0.00609325044656876, std=0.0008284038615378705, value=None), FeatureWeight(feature='Seats', weight=0.006048152654279415, std=0.002379493036709886, value=None), FeatureWeight(feature='New_Price', weight=0.005968360458626406, std=0.001678967802585039, value=None), FeatureWeight(feature='Location_Hyderabad', weight=0.0035997732017195266, std=0.0007842847404497202, value=None), FeatureWeight(feature='Fuel_Type_Diesel', weight=0.00315861457704288, std=0.002149416782300819, value=None), FeatureWeight(feature='Location_Coimbatore', weight=0.0028645533951302577, std=0.0008198439751993861, value=None), FeatureWeight(feature='Fuel_Type_Petrol', weight=0.002071351883756375, std=0.001547880345674174, value=None), FeatureWeight(feature='Location_Delhi', weight=0.0018747644648694434, std=0.0004350059688025879, value=None), FeatureWeight(feature='Location_Bangalore', weight=0.001853148254769041, std=0.0005075304630529667, value=None), FeatureWeight(feature='Location_Mumbai', weight=0.0017512046121957348, std=0.0005356797886281268, value=None), FeatureWeight(feature='Owner_Type_First', weight=0.0016587332251543042, std=0.0006346900735048783, value=None), FeatureWeight(feature='Location_Jaipur', weight=0.0015917854264510213, std=0.0005455895399981237, value=None), FeatureWeight(feature='Location_Pune', weight=0.0015244382122733466, std=0.0004900811305923103, value=None), FeatureWeight(feature='Owner_Type_Second', weight=0.0013071355189752413, std=0.00046366344494510686, value=None)], remaining=8), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ],
      "text/html": "\n    <style>\n    table.eli5-weights tr:hover {\n        filter: brightness(85%);\n    }\n</style>\n\n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n    <thead>\n    <tr style=\"border: none;\">\n        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n    </tr>\n    </thead>\n    <tbody>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.5970\n                \n                    &plusmn; 0.0260\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Power\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 88.84%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.2595\n                \n                    &plusmn; 0.0153\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Year\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 96.55%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0484\n                \n                    &plusmn; 0.0208\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Engine\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 98.10%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0206\n                \n                    &plusmn; 0.0070\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Mileage\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 98.16%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0198\n                \n                    &plusmn; 0.0052\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Kilometers_Driven\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 98.93%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0091\n                \n                    &plusmn; 0.0064\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Transmission\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.19%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0061\n                \n                    &plusmn; 0.0017\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Kolkata\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.20%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0060\n                \n                    &plusmn; 0.0048\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Seats\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.20%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0060\n                \n                    &plusmn; 0.0034\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                New_Price\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.44%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0036\n                \n                    &plusmn; 0.0016\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Hyderabad\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0032\n                \n                    &plusmn; 0.0043\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Fuel_Type_Diesel\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.52%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0029\n                \n                    &plusmn; 0.0016\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Coimbatore\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.62%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0021\n                \n                    &plusmn; 0.0031\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Fuel_Type_Petrol\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.65%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0019\n                \n                    &plusmn; 0.0009\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Delhi\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.65%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0019\n                \n                    &plusmn; 0.0010\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Bangalore\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.66%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0018\n                \n                    &plusmn; 0.0011\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Mumbai\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.68%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0017\n                \n                    &plusmn; 0.0013\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Owner_Type_First\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.68%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0016\n                \n                    &plusmn; 0.0011\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Jaipur\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.69%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0015\n                \n                    &plusmn; 0.0010\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Pune\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.73%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0013\n                \n                    &plusmn; 0.0009\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Owner_Type_Second\n            </td>\n        </tr>\n    \n    \n        \n            <tr style=\"background-color: hsl(120, 100.00%, 99.73%); border: none;\">\n                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n                    <i>&hellip; 8 more &hellip;</i>\n                </td>\n            </tr>\n        \n    \n    </tbody>\n</table>\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n\n"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "explain_rf_feature_importance(reg, feature_names=list(train.columns))"
   ]
  },
  {
   "source": [
    "## Hyperparameters selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': [10, 15, 20, None],\n",
    "    'min_samples_split': [2, 8, 10],\n",
    "    'max_features': [1/3, 1/4, 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_reg = GridSearchCV(RandomForestRegressor(n_estimators=100, random_state=0), param_grid=params, \n",
    "                                                cv=cv, scoring='neg_mean_squared_error', verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Wall time: 31.7 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestRegressor(random_state=0), n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 15, 20, None],\n",
       "                         'max_features': [0.3333333333333333, 0.25, 'auto'],\n",
       "                         'min_samples_split': [2, 8, 10]},\n",
       "             scoring='neg_mean_squared_error', verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "%%time\n",
    "grid_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, max_features=0.3333333333333333,\n",
       "                      random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "grid_reg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg = RandomForestRegressor(n_estimators=120, max_features=1/3,\n",
    "                                max_depth=20, random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(best_reg, X, y, cv=cv)\n",
    "y_pred = pt.inverse_transform(y_pred.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16.80806608493037, 1.5166557705908172)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "mean_squared_error(Y, y_pred), mean_absolute_error(Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Explanation(estimator='RandomForestRegressor(max_depth=20, max_features=0.3333333333333333,\\n                      random_state=0)', description='\\nRandom forest feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=True, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='Power', weight=0.32321143896186055, std=0.19711206768328887, value=None), FeatureWeight(feature='Engine', weight=0.19008808757252643, std=0.17789481949842936, value=None), FeatureWeight(feature='Year', weight=0.18363888397706396, std=0.04377769818541184, value=None), FeatureWeight(feature='Transmission', weight=0.09445336433784508, std=0.12472803792239942, value=None), FeatureWeight(feature='Kilometers_Driven', weight=0.04348232756404018, std=0.016906418734594326, value=None), FeatureWeight(feature='Mileage', weight=0.037496965678514994, std=0.022316100515432088, value=None), FeatureWeight(feature='Fuel_Type_Diesel', weight=0.03438764666048546, std=0.05954107361851123, value=None), FeatureWeight(feature='Fuel_Type_Petrol', weight=0.02186715748596066, std=0.044400445712149614, value=None), FeatureWeight(feature='New_Price', weight=0.01589734123897392, std=0.018085819244507348, value=None), FeatureWeight(feature='Seats', weight=0.010545426493846741, std=0.00874863849646012, value=None), FeatureWeight(feature='Owner_Type_First', weight=0.008624492108730163, std=0.009361422366346139, value=None), FeatureWeight(feature='Location_Kolkata', weight=0.00772024507922997, std=0.0028545611258892416, value=None), FeatureWeight(feature='Location_Coimbatore', weight=0.005032232413788082, std=0.0037119862859520208, value=None), FeatureWeight(feature='Location_Hyderabad', weight=0.003371410536394375, std=0.0007650951400313507, value=None), FeatureWeight(feature='Location_Jaipur', weight=0.0025399135492083307, std=0.0015989012970595222, value=None), FeatureWeight(feature='Owner_Type_Second', weight=0.002539503453538539, std=0.002506170393333172, value=None), FeatureWeight(feature='Location_Mumbai', weight=0.002330024756930819, std=0.001016300450471793, value=None), FeatureWeight(feature='Location_Pune', weight=0.002162292751405986, std=0.0009581502206096289, value=None), FeatureWeight(feature='Location_Delhi', weight=0.002014910143496623, std=0.0005004033438407512, value=None), FeatureWeight(feature='Owner_Type_Third', weight=0.0019428859568541093, std=0.0018393957680369842, value=None)], remaining=8), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ],
      "text/html": "\n    <style>\n    table.eli5-weights tr:hover {\n        filter: brightness(85%);\n    }\n</style>\n\n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n    <thead>\n    <tr style=\"border: none;\">\n        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n    </tr>\n    </thead>\n    <tbody>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.3232\n                \n                    &plusmn; 0.3942\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Power\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 86.21%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.1901\n                \n                    &plusmn; 0.3558\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Engine\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 86.54%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.1836\n                \n                    &plusmn; 0.0876\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Year\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 91.55%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0945\n                \n                    &plusmn; 0.2495\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Transmission\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 95.09%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0435\n                \n                    &plusmn; 0.0338\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Kilometers_Driven\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 95.57%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0375\n                \n                    &plusmn; 0.0446\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Mileage\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 95.83%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0344\n                \n                    &plusmn; 0.1191\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Fuel_Type_Diesel\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 96.96%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0219\n                \n                    &plusmn; 0.0888\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Fuel_Type_Petrol\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 97.57%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0159\n                \n                    &plusmn; 0.0362\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                New_Price\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 98.18%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0105\n                \n                    &plusmn; 0.0175\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Seats\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 98.42%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0086\n                \n                    &plusmn; 0.0187\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Owner_Type_First\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 98.54%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0077\n                \n                    &plusmn; 0.0057\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Kolkata\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 98.91%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0050\n                \n                    &plusmn; 0.0074\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Coimbatore\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.18%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0034\n                \n                    &plusmn; 0.0015\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Hyderabad\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.33%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0025\n                \n                    &plusmn; 0.0032\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Jaipur\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.33%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0025\n                \n                    &plusmn; 0.0050\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Owner_Type_Second\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0023\n                \n                    &plusmn; 0.0020\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Mumbai\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.40%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0022\n                \n                    &plusmn; 0.0019\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Pune\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.43%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0020\n                \n                    &plusmn; 0.0010\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Location_Delhi\n            </td>\n        </tr>\n    \n        <tr style=\"background-color: hsl(120, 100.00%, 99.44%); border: none;\">\n            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n                0.0019\n                \n                    &plusmn; 0.0037\n                \n            </td>\n            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n                Owner_Type_Third\n            </td>\n        </tr>\n    \n    \n        \n            <tr style=\"background-color: hsl(120, 100.00%, 99.44%); border: none;\">\n                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n                    <i>&hellip; 8 more &hellip;</i>\n                </td>\n            </tr>\n        \n    \n    </tbody>\n</table>\n    \n\n    \n\n\n    \n\n    \n\n    \n\n    \n\n    \n\n    \n\n\n\n"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "explain_rf_feature_importance(grid_reg.best_estimator_, feature_names=list(train.columns))"
   ]
  },
  {
   "source": [
    "#### Немного получилось улучшить качество с перебором гиперпараметров."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Задание 1.2. Использование рандомизированного поиска гиперпараметров"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование GridSearch может привести к тому, что придется перебирать слишком много комбинаций параметров, так как их общее количество равно произведению уникальных значений каждого из перебираемых параметров. Поэтому, часто имеет смысл использовать другие варианты перебора. И самым простым из них является случайный поиск (RandomizedSearchCV).\n",
    "\n",
    "В этом случае вместо сетки (param_grid) вам нужно указать распределения или конкретные списки значений требуемых параметров, откуда будут случайным образом выбираться значения. Длительность поиска контролируется с помощью параметра n_iter (например, 250). На практике оказывается, что случайный перебор параметров дает хорошие результаты за намного более короткое время.\n",
    "\n",
    "\n",
    "Основные параметры случайного леса дискретные, поэтому вам предлагается указывать распределения в види списков значений, а не распределений из scipy(как это в некоторых случаях делается в документации для линейных моделей с параметрами С и l1_ratio, а вам, возможно, захочется делать для некоторых параметров бустинга). Если параметров много, то удобно воспользоваться range:\n",
    "\n",
    "param_distr = {'max_depth': list(range(3, 12)) + [None]),\n",
    "               'min_samples_split': range(2, 200, 5)}\n",
    "               \n",
    "               \n",
    "Сравните время на перебор разумного числа параметров в рандомизированном поиске и полного перебора по сетке. Сравните итоговые параметры и качество моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distr = {\n",
    "    'max_depth': list(range(3, 20)) + [None],\n",
    "    'min_samples_split': range(2, 200, 5),\n",
    "    'max_features': [1/3, 1/4, 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_reg = RandomizedSearchCV(RandomForestRegressor(n_estimators=100, random_state=0),\n",
    "                            param_distr, n_iter=180, cv=cv, scoring='neg_mean_squared_error',\n",
    "                            verbose=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "Wall time: 12min 54s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "                   estimator=RandomForestRegressor(random_state=0), n_iter=180,\n",
       "                   param_distributions={'max_depth': [3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                      11, 12, 13, 14, 15, 16,\n",
       "                                                      17, 18, 19, None],\n",
       "                                        'max_features': [0.3333333333333333,\n",
       "                                                         0.25, 'auto'],\n",
       "                                        'min_samples_split': range(2, 200, 5)},\n",
       "                   random_state=0, scoring='neg_mean_squared_error',\n",
       "                   verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "source": [
    "%%time\n",
    "rand_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=18, min_samples_split=7, random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "source": [
    "rand_reg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestRegressor(n_estimators=100, max_depth=18, min_samples_split=7,\n",
    "                            n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(best_reg, X, y, cv=cv)\n",
    "y_pred = pt.inverse_transform(y_pred.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16.808066084930367, 1.516655770590817)"
      ]
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "source": [
    "mean_squared_error(Y, y_pred), mean_absolute_error(Y, y_pred)"
   ]
  },
  {
   "source": [
    "#### Времени на случайный поиск по сетке потребовалось больше конкретно в данном случае, зато мы смогли задать больше параметров (то есть потенциально мы бы смогли еще улучшить качество модели), но, если бы мы сделали полный перебор по сетке с такими же параметрами, времени бы затратилось куда больше."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.3 (На 9). Упрощенная реализация случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, \\\n",
    "    recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вам предлагается написать упрощенную реализацию случайного леса для задачи классификации. Для этого мы будем считать, что дерево у нас уже есть.\n",
    "\n",
    "\n",
    "Необходимо определить методы fit, predict_proba и predict для заготовки класса ниже. Необходимо сделать следующее:\n",
    "1. Реализовать бутстреп и метод подпространств для получения выборки для каждого нового дерева в ансамбле. Для этого рекомендуется использовать np.random.choice с повторениями и без повторений. \n",
    "2. На каждом таком датасете обучать решающее дерево для простоты передавая ему только параметры max_depth,  min_samples_split и criterion. Остальные параметры оставить по умолчанию\n",
    "3. Повторять этот процесс в цикле количество раз, указанное в n_estimamtors. Все деревья добавлять в list _trees\n",
    "4. Для предсказания вероятностей в цикле предсказать вероятности каждым деревом и усреднить. Для предсказания класса передавать дополнительно порог th. Если он None, то должен использоваться порог 0.5\n",
    "\n",
    "\n",
    "После сравните вашу реализацию и RandomForestClassifier с выбранными параметрами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRandomForestClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, n_estimators=100,\n",
    "                 criterion='gini',\n",
    "                 max_features='auto',\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.criterion = criterion\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        \n",
    "        self._trees = []\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Bootstrap.  \n",
    "            bootstrap_indices = np.random.choice(X.shape[0], X.shape[0])\n",
    "            X_train = X[bootstrap_indices]\n",
    "            y_train = y[bootstrap_indices]\n",
    "\n",
    "            clf_tree = DecisionTreeClassifier(criterion=self.criterion, max_depth=self.max_depth, max_features=self.max_features,\n",
    "                                                min_samples_split=self.min_samples_split, random_state=42)\n",
    "            \n",
    "            clf_tree.fit(X_train, y_train)\n",
    "\n",
    "            self._trees.append(clf_tree)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_pred = [clf.predict_proba(X) for clf in self._trees]\n",
    "        \n",
    "        return np.mean(y_pred, axis=0)\n",
    "\n",
    "    def predict(self, X, th=None):\n",
    "        if th is None:\n",
    "            th = 0.5\n",
    "\n",
    "        return (self.predict_proba(X)[:, 1] > th).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   CustomerID  Gender  Senior Citizen Partner Dependents  Tenure  \\\n",
       "0  7590-VHVEG       0               0     Yes         No       1   \n",
       "1  5575-GNVDE       1               0      No         No      34   \n",
       "2  3668-QPYBK       1               0      No         No       2   \n",
       "3  7795-CFOCW       1               0      No         No      45   \n",
       "4  9237-HQITU       0               0      No         No       2   \n",
       "\n",
       "  Phone Service    Multiple Lines Internet Service Online Security  ...  \\\n",
       "0            No  No phone service              DSL              No  ...   \n",
       "1           Yes                No              DSL             Yes  ...   \n",
       "2           Yes                No              DSL             Yes  ...   \n",
       "3            No  No phone service              DSL             Yes  ...   \n",
       "4           Yes                No      Fiber optic              No  ...   \n",
       "\n",
       "  Device Protection Tech Support Streaming TV Streaming Movies  \\\n",
       "0                No           No           No               No   \n",
       "1               Yes           No           No               No   \n",
       "2                No           No           No               No   \n",
       "3               Yes          Yes           No               No   \n",
       "4                No           No           No               No   \n",
       "\n",
       "         Contract Paperless Billing             Payment Method  \\\n",
       "0  Month-to-month               Yes           Electronic check   \n",
       "1        One year                No               Mailed check   \n",
       "2  Month-to-month               Yes               Mailed check   \n",
       "3        One year                No  Bank transfer (automatic)   \n",
       "4  Month-to-month               Yes           Electronic check   \n",
       "\n",
       "  Monthly Charges  Total Charges  Churn  \n",
       "0           29.85          29.85     No  \n",
       "1           56.95        1889.50     No  \n",
       "2           53.85         108.15    Yes  \n",
       "3           42.30        1840.75     No  \n",
       "4           70.70         151.65    Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CustomerID</th>\n      <th>Gender</th>\n      <th>Senior Citizen</th>\n      <th>Partner</th>\n      <th>Dependents</th>\n      <th>Tenure</th>\n      <th>Phone Service</th>\n      <th>Multiple Lines</th>\n      <th>Internet Service</th>\n      <th>Online Security</th>\n      <th>...</th>\n      <th>Device Protection</th>\n      <th>Tech Support</th>\n      <th>Streaming TV</th>\n      <th>Streaming Movies</th>\n      <th>Contract</th>\n      <th>Paperless Billing</th>\n      <th>Payment Method</th>\n      <th>Monthly Charges</th>\n      <th>Total Charges</th>\n      <th>Churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7590-VHVEG</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>1</td>\n      <td>No</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Electronic check</td>\n      <td>29.85</td>\n      <td>29.85</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5575-GNVDE</td>\n      <td>1</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>34</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>Mailed check</td>\n      <td>56.95</td>\n      <td>1889.50</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3668-QPYBK</td>\n      <td>1</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>2</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Mailed check</td>\n      <td>53.85</td>\n      <td>108.15</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7795-CFOCW</td>\n      <td>1</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>45</td>\n      <td>No</td>\n      <td>No phone service</td>\n      <td>DSL</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>Bank transfer (automatic)</td>\n      <td>42.30</td>\n      <td>1840.75</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9237-HQITU</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>2</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Fiber optic</td>\n      <td>No</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Electronic check</td>\n      <td>70.70</td>\n      <td>151.65</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df, y = \\\n",
    "df.loc[:, (df.columns != 'Churn') & (df.columns != 'CustomerID')].copy(deep=True), df['Churn'].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in X_df.columns:\n",
    "    col_values = X_df[col_name].value_counts()\n",
    "    if set(col_values.keys()) == set(['Yes', 'No']):\n",
    "        X_df.loc[:, col_name] = X_df[col_name].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_col_names = ['Tenure', 'Monthly Charges', 'Total Charges']\n",
    "scaler = StandardScaler()\n",
    "real_cols = scaler.fit_transform(df.loc[:, real_col_names])\n",
    "X_df[real_col_names] = real_cols\n",
    "\n",
    "y = y.apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "X_df.fillna(value=0, inplace=True)\n",
    "\n",
    "X_df = pd.get_dummies(X_df)\n",
    "X = X_df.to_numpy(dtype=float)\n",
    "y = y.to_numpy(dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpRandomForestClf = SimpleRandomForestClassifier(n_estimators=100, max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SimpleRandomForestClassifier(max_depth=20)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "simpRandomForestClf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = simpRandomForestClf.predict_proba(X_test)\n",
    "y_pred = simpRandomForestClf.predict(X_test, th=ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision: 48.084%\nRecall: 80.000%\nF1 score: 60.065% \nROC-AUC score: 82.816%\n"
     ]
    }
   ],
   "source": [
    "prec = precision_score(y_test, y_pred) * 100\n",
    "recall = recall_score(y_test, y_pred) * 100\n",
    "f_score = f1_score(y_test, y_pred) * 100\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1]) * 100\n",
    "print('Precision: {:.3f}%\\n'.format(prec) + \n",
    "        'Recall: {:.3f}%\\nF1 score: {:.3f}% \\nROC-AUC score: {:.3f}%'.format(\n",
    "        recall, f_score, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "randForest = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "randForest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = randForest.predict_proba(X_test)\n",
    "y_pred = randForest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Precision: 60.498%\nRecall: 49.275%\nF1 score: 54.313% \nROC-AUC score: 82.568%\n"
     ]
    }
   ],
   "source": [
    "prec = precision_score(y_test, y_pred) * 100\n",
    "recall = recall_score(y_test, y_pred) * 100\n",
    "f_score = f1_score(y_test, y_pred) * 100\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1]) * 100\n",
    "print('Precision: {:.3f}%\\n'.format(prec) + \n",
    "        'Recall: {:.3f}%\\nF1 score: {:.3f}% \\nROC-AUC score: {:.3f}%'.format(\n",
    "        recall, f_score, roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во второй части лабораторной работы вы будете использовать датасет из прошлого \"развлекательного\" соревнования на Kaggle и (опционально) обучать модель и выполнять другие действия напрямую в kaggle kernels. \n",
    "В рамках соревнования была поставлена задача предсказания нормализованного от 0 до 1 места, которое занял игрок в матче в компьютерной игре PUBG на основании игровой статистики по этому матчу.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Для этого вам нужно:\n",
    "1. Создать аккаунт на kaggle\n",
    "2. Перейти в соревнование https://www.kaggle.com/c/pubg-finish-placement-prediction\n",
    "3. Согласиться с правилами и получить к нему доступ\n",
    "4. Нажать Late Submission и New Notebook.\n",
    "\n",
    "В итоге у вас откроется нечто похожее на Jupyter Notebook в обертке Kaggle с доступом к датасету и возможностью использовать большинство популярных библиотек машинного обучения. Таким образом, не будет необходимости нагружать личный ноутбук датасетом, который в этот раз будет намного больше предыдущих.\n",
    "\n",
    "Сессия автоматически оборвется через несколько часов, но вам времени хватит.\n",
    "\n",
    "\n",
    "В конце нужно будет сгенерировать ответ в формате файла sample_submission_V2.csv и выполнить Late Submission следующими действиями:\n",
    "1. В верхнем правом углу интерфейса ноутбука нажать Save Version\n",
    "2. Там выбрать опцию Save & Commit и сохранить. Эта кнопка привет к тому, что весь ваш ноутбук будет пересчитан, а предсказания, которые вы сохраните в конце как preds.to_csv('submission.csv') можно будет отправить на оценку качества\n",
    "3. После завершения пересчета ноутбука вы сможете открыть готовый файл и нажать там на вкладке output кнопку Submit.\n",
    "\n",
    "В итоге вам нужно прислать мне (лектору) скриншот вашего лучшего сабмита и метрику качества модели **текстом**, чтобы я мог составить чисто на вашей группе таблицу. За относительные места вы получите **отдельную** оценку. \n",
    "\n",
    "Все вместе это звучит сложно, но в начале практики я покажу с помощью шаринга экрана, что нужно делать.\n",
    "\n",
    "\n",
    "**Полезный совет**: В итоговом ноутбуке вам нет необходимости повторять все вычисления из задания (например, перебор гиперпараметров), а только повторить инженерию признаков и обучить лучшую модель. Он может быть отдельным от того ноутбука, в котором вы проведете EDA и непосредственно выполните лабу.\n",
    "\n",
    "\n",
    "P.S. Описание датасета приведено на этой странице https://www.kaggle.com/c/pubg-finish-placement-prediction/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.1 Работа с lightgbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека для градиентного бустинга lightgbm умеет работать с категориальными признаками без предварительного кодирования. Для этого их нужно только указать и преобразовать в числа. Сделать это можно с помощью OrdinalEncoder. В текущем датасете не так много категориальных переменных, поэтому это оказывается не принципиально (но в рамках курса вам это еще понадобится). Обратите внимание, что для тренировочного датасета у энкодера нужно вызывать fit_transform, а для тестового только transform. И ответьте мне на вопрос: почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С lgb удобно работать следующим образом.\n",
    "1. Вы разбиваете ваши данные на тренировочные и валидационные и создаете с помощью lgb.Dataset два объекта dtrain и dval\n",
    "2. Используете lgb.train, чтобы обучить модель. Все параметры обучения удобно хранить в одном словаре params\n",
    "3. Предсказываете на тестовых данных с помощью полученной модели\n",
    "\n",
    "Ниже показан близкий к реальностти псевдокод (обратите внимание, что можно напрямую разделить ваш финальный датафрейм и указывать переменными конкретный набор признаков. Так вам будет удобнее экспериментировать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['foo', 'bar', 'baz']\n",
    "cagegorical_features = ['baz']\n",
    "label = 'your_target_column'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(data=df_train[features],\n",
    "                     label=df_train[label],\n",
    "                     feature_name=features,\n",
    "                     categorical_feature=categorical_feature)\n",
    "\n",
    "dval = lgb.Dataset(data=df_val[features],\n",
    "                   label=df_val[label],\n",
    "                   feature_name=features,\n",
    "                   categorical_feature=categorical_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведен пример списка параметров, который делает следующее\n",
    "1. Устанавливает обычный тип бустинга (другие - это goss и dart)\n",
    "2. Говорит использовать в качестве функции потерь и метрики mean absolute error (целевая метрика в этой задаче)\n",
    "3. Ограничивает максимальное число листьев в дереве до 40\n",
    "4. Отключает ограничение на максимальную глубину. Это один из приемов, введенный lightgbm, при которой мы можем ограничивать сложность дерева не глубиной, а максимальным количеством листьев. Однако, можно и явно ограничивать глубину. Попробовать не помешает.\n",
    "5. Устанавливает скорость обучения 0.1. Рекомендуется подбирать параметры и проводить эксперименты именно с  такой скоростью или максимум скоростью 0.07-0.05, а для финального предсказания снизить ее до, например, 0.01\n",
    "6. Устанавливает минимальное количество примеров для одного листа в 10. Параметр очень похож на тот, который вы уже использовали для деревьев и леса.\n",
    "7. feature_fraction - для метода подпространств, bagging_fraction - для сэмплирования из исходного датасета (в этом случае без повторений)\n",
    "8. Указывает 6 тредов (по количеству физических ядер). У вас этот параметр может быть другим для оптимальной работы\n",
    "9. Устанавливает некоторые параметры обработки категориальных признаков. Предлагается вам разобраться с их назначением самостоятельно\n",
    "\n",
    "\n",
    "Все параметры и другие советы по их тюнингу смотреть вот тут. https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "\n",
    "Для достижения оптимального результата вам, вероятно, захочется использовать еще какие-то.\n",
    "\n",
    "P.S. Набор гиперпараметров приведен для примера и упрощения вашей работы. Но это не значит, что значения гиперпараметров оптимальны, они местами взяты от балды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'mae',\n",
    "        'metric': 'mae',\n",
    "        'num_leaves': 40,\n",
    "        'max_depth': None,\n",
    "        'learning_rate': 0.1,\n",
    "        'min_data_in_leaf': 10,\n",
    "        'feature_fraction': 0.6,\n",
    "        'bagging_fraction': 0.6,\n",
    "        'bagging_freq': 1,\n",
    "        #'bagging_freq': 5,\n",
    "        'num_threads': 6,\n",
    "    \n",
    "        'cat_smooth': 10,\n",
    "        'max_cat_threshold': 16,\n",
    "        'max_cat_to_onehot': 4,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код ниже обучит модель на dtrain, произведет раннюю остановку по dval, используя params в качестве гиперпараметров. Всегда имеет смысл поставить очень много итераций бустинга, но контролировать обучение с помощью ранней остановки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.train(params, dtrain, \n",
    "              # указываем валидационный датасет и тренировочный (хотим посмотреть качество и на нем тоже)\n",
    "              # однако он будет проигнорирован механикой ранней остановки\n",
    "              valid_sets=(dtrain, dval),\n",
    "              # поставим очень большое количество итераций бустинга\n",
    "              num_boost_round=10000,\n",
    "              # но будем использовать раннюю остановку по качеству на валидационной выборке\n",
    "              early_stopping_rounds=25,\n",
    "              #будем выводить промежуточные результаты каждые 25 итераций\n",
    "              verbose_eval=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте добавить другие параметры, осмысленно поменять их значения (усилив или ослабив разные способы регуляризации и т.д.) перед тем как переходить к их подбору."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученную модель можно использовать для предсказания с помощью model.predict на новых данных. Обратите внимание, что передавать для предсказаний нужно не lgb.Dataset, а pd.DataFrame только с нужными столбцами, т.е. условно test_df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.2. Особенности подбора гиперпараметров градиентного бустинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В контексте подбора гиперпараметров в градиентом бустинге интересно проявляется функционал ранней остановки. \n",
    "С одной стороны есть LGBMRegressor, реализующий интерфейс, который можно использовать в Grid- или RandomizedSeach. Однако, в этом интерфейсе возможность ранней остановки есть только в методе fit. И оказывается, что учесть раннюю остановку в переборе гиперпараметров не получается. В итоге у вас каждый раз будет обучаться то количество деревьев, которое вы укажете в n_estimators. Это может привести к недообученным или переобученным деревьям, так как вы можете или указать слишком мало, или слишком много. \n",
    "\n",
    "Корректный перебор гиперпараметров возможен, если вы выбираете много num_boost_round и указываете early_stopping_rounds как в lgb.train выше. Попробуем это сделать одним из возможных способов\n",
    "\n",
    "Для того, чтобы реализовать настройку гиперпараметров правильно вам нужно:\n",
    "1. Использовать lgb.cv (интерфейс практически совпадает с lgb.cv), чтобы с помощью кросс-валидации и ранней остановки получать качество работы алгоритма на указанных params\n",
    "2. Реализовать функцию eval_lgb, которая на вход принимает указанный список гиперпараметров, а на выходе возвращает значение метрики качества. ВНИМАНИЕ, некоторые параметры (objective, metric и т.д.) должны быть каждый раз одинаковы. Их передавать не нужно.\n",
    "3. Использовать ParameterGrid или ParameterSampler и sklearn.model_selection для итерации по возможным наборам или указанному числу сэмплов (в зависисмости выбранного вами способа)\n",
    "4. Вычислить значение метрики на выбранных вами комбинациях, отсортировать и получить лучшее\n",
    "5. Обучить ваш алгоритм с помощью lgb.train на лучшем наборе параметров, попробовав дополнительно снизить скорость обучения\n",
    "\n",
    "Ниже представлена заготовка функции eval_lgb. Не забудьте правильно указать параметры кросс-валидации и зафиксировать random_state!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lgb(params):\n",
    "    base_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'mae',\n",
    "        'metric': 'mae',\n",
    "        'num_threads': 6\n",
    "    }\n",
    "    base_params.update(params)\n",
    "    results = lgb.cv(...)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.3 (10) Байесовская оптимизация для подбора гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Байесовская оптимизация - это один из продвинутых способов перебора гиперпараметров модели, имеющий некоторые общие черты с рандомизированным поиском. В этом случае оптимизация состоит из двух частей: \n",
    "- exploration - исследование новых регионов поверхности гиперпараметров, на который происходит поиск оптимальных решений.\n",
    "- exploitation - более подробный разбор регионов, для которых уже известно, что там качество лучше\n",
    "\n",
    "Первая часть и есть наш случайный поиск, а вторая - использования баейсовского подхода к статистике ([вот тут крутой, но довольно сложный курс](https://www.coursera.org/learn/bayesian-methods-in-machine-learning)) для генерации новых комбинаций гиперпараметров, которые могут давать высокое качество. \n",
    "\n",
    "Для желающих подробно ознакомиться с темой оставляю следующию ссылку: https://distill.pub/2020/bayesian-optimization/\n",
    "\n",
    "В рамках этого задания я вам предлагаю познакомиться с инструментом в утилитарном стиле. Вам предлагается провести оптимизацию гиперпараметров вашей модели с использованием библиотеки bayesian-optimization (conda install -c conda-forge bayesian-optimization) для lightgbm. https://github.com/fmfn/BayesianOptimization\n",
    "\n",
    "Для этого вам нужно взять функцию eval_lgb и, возможно, адаптировать ее под новый вариант использования.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd03f800561dde6209f0c647b1ec24b295364b37801e2a63d392a491285ef4d5a88",
   "display_name": "Python 3.7.6 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}